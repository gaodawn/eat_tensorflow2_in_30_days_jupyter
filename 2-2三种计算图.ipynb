{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2、三种计算图\n",
    "有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。  \n",
    "\n",
    "在Tensorflow1.0时代，采用的是静态计算图，需要先使用Tensorflow的各种算子创建计算图，然后再开启一个会话，显式执行计算图。   \n",
    "\n",
    "而在2.0时代，采用的是动态计算图，即计算每一个算子后，该算子会被动态加入到隐含的默认计算图中立即执行得到结果，而无需开启session。  \n",
    "\n",
    "使用动态计算图的好处是方便调试程序，它会让tensorflow代码的表现和python原生代码的表现一样，写起来就写numpy一样，各种日志打印，控制流全部都是可以使用的。  \n",
    "\n",
    "使用动态计算图的缺点是运行效率会相对低一些。因为会有许多次python进程和c++进程之间的通信。而静态计算图构建完成之后几乎全部在tensorflow内核上使用c++代码执行，效率更高。此外静态图会对计算步骤进行一定的优化，剪去和结果无关的计算步骤。   \n",
    "\n",
    "如果需要在tensorflow2.0中使用静态图，可以使用@tf.function装饰器将普通python函数转换成对应的tensorflow计算图构建代码。运行该函数就相当于在tensorflow1.0中用session执行代码，使用tf.function构建静态图的方式叫做Autograph.   \n",
    "\n",
    "### 一、计算图简介\n",
    "计算图由节点(nodes)和线(edges)组成。  \n",
    "\n",
    "节点表示操作符Operator，或者称之为算子，线表示计算间的依赖。\n",
    "\n",
    "实线表示有数据传递依赖，传递的数据即张量。\n",
    "\n",
    "虚线通常可以表示控制依赖，即执行先后顺序。  \n",
    "\n",
    "![](\"data/strjoin_graph.png\")  \n",
    "\n",
    "\n",
    "### 二、静态计算图\n",
    "在tensorflow1.0中，使用静态计算图分为两步，第一步定义计算图，第二步在会话中执行计算图。  \n",
    "\n",
    "#### Tensorflow1.0 静态计算图范例(没装1.0，无法运行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eb101959f606>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'join'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(name = 'x',shape=[],dtype=tf.string)\n",
    "    y = tf.placeholder(name = 'y',shape=[],dtype=tf.string)\n",
    "    z = tf.string_join([x,y],name = 'join',separator='')\n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(sess.run(fetches=z,feed_dict={x:\"hello\",y:\"world\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow2.0怀旧版静态计算图\n",
    "Tensorflow2.0为了确保对老版本tensorflow项目的兼容性，在tf.compat.v1子模块中保留了对Tensorflow1.0那种静态计算图构建风格的支持。  \n",
    "可称之为怀旧版静态计算图，已经不推荐使用了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'helloworld'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.compat.v1.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.compat.v1.placeholder(name = 'x',shape=[],dtype=tf.string)\n",
    "    y = tf.compat.v1.placeholder(name = 'y',shape=[],dtype=tf.string)\n",
    "    z = tf.strings.join([x,y],name = 'join',separator='')\n",
    "with tf.compat.v1.Session(graph=g) as sess:\n",
    "    print(sess.run(fetches=z,feed_dict={x:\"hello\",y:\"world\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、动态计算图\n",
    "在tensorflow2.0中，使用的是动态计算图和Autograph。  \n",
    "\n",
    "在1.0中，使用静态计算图分为两步，第一步定义计算图，第二步在会话中执行计算图。  \n",
    "\n",
    "动态计算图已经不区分计算图的定义和执行了，而是定义后立即执行。因此称之为Eager Excution.  \n",
    "\n",
    "Eager这个应为单词的愿意是“迫不及待的”，也就是立即执行的意思。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(\"hello\")\n",
    "y = tf.constant(\"world\")\n",
    "z = tf.strings.join([x,y],separator=\" \")\n",
    "tf.print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "tf.Tensor(b'hello world', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# 可以将动态计算图代码的输入和输出关系封装成函数\n",
    "\n",
    "def strjoin(x,y):\n",
    "    z =  tf.strings.join([x,y],separator = \" \")\n",
    "    tf.print(z)\n",
    "    return z\n",
    "\n",
    "result = strjoin(tf.constant(\"hello\"),tf.constant(\"world\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、Tensorflow2.0的Autograph\n",
    "动态计算图运行效率比较低。   \n",
    "\n",
    "可以使用@tf.function装饰器将普通python函数转换成和tensorflow1.0中对应的静态计算图构建代码。  \n",
    "\n",
    "在TensorFlow1.0中，使用计算图分两步，第一步定义计算图，第二步在会话中执行计算图。\n",
    "\n",
    "在TensorFlow2.0中，如果采用Autograph的方式使用计算图，第一步定义计算图变成了定义函数，第二步执行计算图变成了调用函数。\n",
    "\n",
    "不需要使用会话了，一些都像原始的Python语法一样自然。\n",
    "\n",
    "实践中，我们一般会先用动态计算图调试代码，然后在需要提高性能的的地方利用@tf.function切换成Autograph获得更高的效率。\n",
    "\n",
    "当然，@tf.function的使用需要遵循一定的规范，我们后面章节将重点介绍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi Mary\n",
      "tf.Tensor(b'Hi Mary', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def strjoin(x,y):\n",
    "    z = tf.strings.join([x,y],separator=\" \")\n",
    "    tf.print(z)\n",
    "    return z\n",
    "\n",
    "result = strjoin(tf.constant(\"Hi\"),tf.constant(\"Mary\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = './data/autograph/%s' % stamp\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "tf.summary.trace_on(graph=True,profiler=True)\n",
    "\n",
    "result = strjoin(\"hello\",\"world\")\n",
    "\n",
    "#将计算图信息写入日志\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(\n",
    "        name=\"autograph\",\n",
    "        step=0,\n",
    "        profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/tangxi.zq/.conda/envs/tf2/bin:/usr/local/bin:/home/tangxi.zq/.conda/envs/torch/bin:/home/tangxi.zq/tangxi/anaconda3/condabin:/sbin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/usr/X11R6/bin:/home/tangxi.zq/.local/bin:/home/tangxi.zq/bin:/home/tangxi.zq/tangxi/anaconda3/bin:/home/tangxi.zq/bin\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#启动 tensorboard在jupyter中的魔法命令\n",
    "import os\n",
    "PATH = os.getenv(\"PATH\")\n",
    "%env PATH = /home/tangxi.zq/.conda/envs/tf2/bin:$PATH\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f0d355a77a98f5da\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f0d355a77a98f5da\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#启动tensorboard\n",
    "%tensorboard --logdir ./data/autograph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
