{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习的训练过程常常非常耗时，一个模型训练几个小时是家常便饭，训练几天也是常有的事情，有时候甚至要训练几十天。\n",
    "\n",
    "训练过程的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代。\n",
    "\n",
    "当数据准备过程还是模型训练时间的主要瓶颈时，我们可以使用更多进程来准备数据。\n",
    "\n",
    "当参数迭代过程成为训练时间的主要瓶颈时，我们通常的方法是应用GPU或者Google的TPU来进行加速。\n",
    "\n",
    "详见《用GPU加速Keras模型——Colab免费GPU使用攻略》\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/68509398\n",
    "\n",
    "无论是内置fit方法，还是自定义训练循环，从CPU切换成单GPU训练模型都是非常方便的，无需更改任何代码。当存在可用的GPU时，如果不特意指定device，tensorflow会自动优先选择使用GPU来创建张量和执行张量计算。\n",
    "\n",
    "但如果是在公司或者学校实验室的服务器环境，存在多个GPU和多个使用者时，为了不让单个同学的任务占用全部GPU资源导致其他同学无法使用（tensorflow默认获取全部GPU的全部内存资源权限，但实际上只使用一个GPU的部分资源），我们通常会在开头增加以下几行代码以控制每个任务使用的GPU编号和显存大小，以便其他同学也能够同时训练模型。\n",
    "\n",
    "在Colab笔记本中：修改->笔记本设置->硬件加速器 中选择 GPU\n",
    "\n",
    "注：以下代码只能在Colab 上才能正确执行。\n",
    "\n",
    "可通过以下colab链接测试效果《tf_单GPU》：\n",
    "\n",
    "https://colab.research.google.com/drive/1r5dLoeJq5z01sU72BX2M5UiNSkuxsEFe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras import * \n",
    "\n",
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    today_ts = tf.timestamp()%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "    \n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "    \n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n",
    "                timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8+timestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 300\n",
    "BATCH_SIZE = 32\n",
    "(x_train,y_train),(x_test,y_test) = datasets.reuters.load_data()\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train,maxlen=MAX_LEN)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test,maxlen=MAX_LEN)\n",
    "\n",
    "MAX_WORDS = x_train.max()+1\n",
    "CAT_NUM = y_train.max()+1\n",
    "\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((x_train,y_train)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()\n",
    "   \n",
    "ds_test = tf.data.Dataset.from_tensor_slices((x_test,y_test)) \\\n",
    "          .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 7)            216874    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 296, 64)           2304      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 148, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 146, 32)           6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 73, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2336)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 46)                107502    \n",
      "=================================================================\n",
      "Total params: 332,856\n",
      "Trainable params: 332,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(MAX_WORDS,7,input_length=MAX_LEN))\n",
    "    model.add(layers.Conv1D(filters = 64,kernel_size = 5,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Conv1D(filters = 32,kernel_size = 3,activation = \"relu\"))\n",
    "    model.add(layers.MaxPool1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(CAT_NUM,activation = \"softmax\"))\n",
    "    return(model)\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Nadam()\n",
    "loss_func = losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_loss = metrics.Mean(name='train_loss')\n",
    "train_metric = metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "valid_loss = metrics.Mean(name='valid_loss')\n",
    "valid_metric = metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features,training = True)\n",
    "        loss = loss_func(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss.update_state(loss)\n",
    "    train_metric.update_state(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def valid_step(model, features, labels):\n",
    "    predictions = model(features)\n",
    "    batch_loss = loss_func(labels, predictions)\n",
    "    valid_loss.update_state(batch_loss)\n",
    "    valid_metric.update_state(labels, predictions)\n",
    "    \n",
    "\n",
    "def train_model(model,ds_train,ds_valid,epochs):\n",
    "    for epoch in tf.range(1,epochs+1):\n",
    "        \n",
    "        for features, labels in ds_train:\n",
    "            train_step(model,features,labels)\n",
    "\n",
    "        for features, labels in ds_valid:\n",
    "            valid_step(model,features,labels)\n",
    "\n",
    "        logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'\n",
    "        \n",
    "        if epoch%1 ==0:\n",
    "            printbar()\n",
    "            tf.print(tf.strings.format(logs,\n",
    "            (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))\n",
    "            tf.print(\"\")\n",
    "            \n",
    "        train_loss.reset_states()\n",
    "        valid_loss.reset_states()\n",
    "        train_metric.reset_states()\n",
    "        valid_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、单GPU使用范例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较GPU和CPU的速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printbar()\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    tf.random.set_seed(0)\n",
    "    a = tf.random.uniform((10000,100),minval = 0,maxval = 3.0)\n",
    "    b = tf.random.uniform((100,100000),minval = 0,maxval = 3.0)\n",
    "    c = a@b\n",
    "    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = 0),axis=0))\n",
    "printbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================11:35:45\n",
      "2.24953795e+11\n",
      "================================================================================11:35:46\n"
     ]
    }
   ],
   "source": [
    "printbar()\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    tf.random.set_seed(0)\n",
    "    a = tf.random.uniform((10000,100),minval = 0,maxval = 3.0)\n",
    "    b = tf.random.uniform((100,100000),minval = 0,maxval = 3.0)\n",
    "    c = a@b\n",
    "    tf.print(tf.reduce_sum(tf.reduce_sum(c,axis = 0),axis=0))\n",
    "printbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================11:41:09\n",
      "Epoch=1,Loss:0.238682106,Accuracy:0.940325081,Valid Loss:2.84660745,Valid Accuracy:0.637132704\n",
      "\n",
      "================================================================================11:41:11\n",
      "Epoch=2,Loss:0.217350081,Accuracy:0.941549778,Valid Loss:2.90742493,Valid Accuracy:0.634461284\n",
      "\n",
      "================================================================================11:41:14\n",
      "Epoch=3,Loss:0.201330855,Accuracy:0.943442464,Valid Loss:2.97029018,Valid Accuracy:0.63223511\n",
      "\n",
      "================================================================================11:41:16\n",
      "Epoch=4,Loss:0.186019182,Accuracy:0.944667101,Valid Loss:3.09040713,Valid Accuracy:0.63357079\n",
      "\n",
      "================================================================================11:41:19\n",
      "Epoch=5,Loss:0.172671407,Accuracy:0.944667101,Valid Loss:3.19806361,Valid Accuracy:0.627337515\n",
      "\n",
      "================================================================================11:41:21\n",
      "Epoch=6,Loss:0.162220448,Accuracy:0.946003139,Valid Loss:3.3207531,Valid Accuracy:0.627782702\n",
      "\n",
      "================================================================================11:41:24\n",
      "Epoch=7,Loss:0.152845606,Accuracy:0.947116435,Valid Loss:3.44447255,Valid Accuracy:0.61843276\n",
      "\n",
      "================================================================================11:41:26\n",
      "Epoch=8,Loss:0.145539612,Accuracy:0.948118448,Valid Loss:3.57534742,Valid Accuracy:0.620213687\n",
      "\n",
      "================================================================================11:41:29\n",
      "Epoch=9,Loss:0.136064023,Accuracy:0.949565828,Valid Loss:3.7002964,Valid Accuracy:0.614870906\n",
      "\n",
      "================================================================================11:41:31\n",
      "Epoch=10,Loss:0.130741939,Accuracy:0.951235831,Valid Loss:3.76797175,Valid Accuracy:0.616651833\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model,ds_train,ds_test,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、多GPU使用范例\n",
    "\n",
    "MirroredStrategy过程简介：\n",
    "\n",
    "训练开始前，该策略在所有 N 个计算设备上均各复制一份完整的模型；\n",
    "每次训练传入一个批次的数据时，将数据分成 N 份，分别传入 N 个计算设备（即数据并行）；\n",
    "N 个计算设备使用本地变量（镜像变量）分别计算自己所获得的部分数据的梯度；\n",
    "使用分布式计算的 All-reduce 操作，在计算设备间高效交换梯度数据并进行求和，使得最终每个设备都有了所有设备的梯度之和；\n",
    "使用梯度求和的结果更新本地变量（镜像变量）；\n",
    "当所有设备均更新本地变量后，进行下一轮训练（即该并行策略是同步的）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此处在colab上使用1个GPU模拟出两个逻辑GPU进行多GPU训练\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 设置两个逻辑GPU模拟多GPU训练\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024),\n",
    "             tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 7)            216874    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 296, 64)           2304      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 148, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 146, 32)           6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 73, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2336)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 46)                107502    \n",
      "=================================================================\n",
      "Total params: 332,856\n",
      "Trainable params: 332,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compile_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0ecf349966ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compile_model' is not defined"
     ]
    }
   ],
   "source": [
    "#增加以下两行代码\n",
    "strategy = tf.distribute.MirroredStrategy()  \n",
    "with strategy.scope(): \n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    model = compile_model(model)\n",
    "    \n",
    "history = model.fit(ds_train,validation_data = ds_test,epochs = 10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、TPU使用范例"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
